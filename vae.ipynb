{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3610jvsc74a57bd0f8ab50291a78bf4d0a9654d671576f4d1e12bd68d7b65ad2304942e6b2f42f4c",
   "display_name": "Python 3.6.10 64-bit ('kongsr-rdkit': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f8ab50291a78bf4d0a9654d671576f4d1e12bd68d7b65ad2304942e6b2f42f4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import pennylane as qml\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pickle.load(open('dataset/training.pkl', 'rb'))\n",
    "validation = pickle.load(open('dataset/validation.pkl', 'rb'))\n",
    "data = set(training + validation)\n",
    "\n",
    "for pdb_id in list(set([i.split('-')[0] for i in os.listdir('dataset/res')])):\n",
    "    if not osp.isfile('dataset/graph/' + pdb_id + '-lig.npy'):\n",
    "        data.discard(pdb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 31\n",
    "reduced_data = []\n",
    "bond = np.zeros((36, 36))\n",
    "atom = np.zeros((36))\n",
    "for pdb_id in list(data):\n",
    "    bond_one_hot, atom_one_hot = pickle.load(open('dataset/onehot/' + pdb_id + '-lig.pkl', 'rb'))\n",
    "    # reverse onehot encoding\n",
    "    for i in range(36):\n",
    "        for j in range(36):\n",
    "            bond[i, j] = np.argmax(bond_one_hot[i, j])\n",
    "        atom[i] = np.argmax(atom_one_hot[i])\n",
    "\n",
    "    # reduce maximum number of heavy atoms to N\n",
    "    # and pad 32 zeros to form 1024=2^n_qubits dimension ligands\n",
    "    if len(atom[atom > 0]) <= N:\n",
    "        reduced_atom = atom[:N]\n",
    "        reduced_bond = bond[:N, :N]\n",
    "        reduced_data.append(np.concatenate((reduced_bond.reshape(-1), \\\n",
    "                            reduced_atom.reshape(-1), np.zeros((32))), axis=0))\n",
    "\n",
    "n_samples = len(reduced_data)\n",
    "train = np.array(reduced_data[:int(n_samples*0.85)])\n",
    "test = np.array(reduced_data[int(n_samples*0.85):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "math.log(train.shape[-1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = train.shape[-1]\n",
    "n_qubits = int(math.log(n_features, 2))\n",
    "latent_dim = 64\n",
    "qml.enable_tape()\n",
    "dev = qml.device(\"default.qubit.tf\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface='tf', diff_method='backprop')\n",
    "def qnode_e(inputs, weights):\n",
    "    qml.templates.AmplitudeEmbedding(features=inputs, wires=range(n_qubits), normalize = True)\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "@qml.qnode(dev, interface='tf', diff_method='backprop')\n",
    "def qnode_d(inputs, weights):\n",
    "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "\n",
    "    return qml.probs(wires=[i for i in range(n_qubits)])\n",
    "\n",
    "weight_shapes_e = {\"weights\": (6, n_qubits, 3)}\n",
    "weight_shapes_d = {\"weights\": (6, n_qubits, 3)}\n",
    "\n",
    "qlayer_e = qml.qnn.KerasLayer(qnode_e, weight_shapes_e, output_dim=n_qubits)\n",
    "qlayer_d = qml.qnn.KerasLayer(qnode_d, weight_shapes_d, output_dim=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            qlayer_e,\n",
    "            layers.Dense(n_qubits)\n",
    "        ])\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            qlayer_d,\n",
    "            layers.Dense(n_features)\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "autoencoder.compile(optimizer=opt, loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(train, train,\n",
    "                epochs=20,\n",
    "                shuffle=True,\n",
    "                validation_data=(test, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}